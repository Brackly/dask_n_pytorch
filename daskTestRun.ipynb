{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brackly/dask_n_pytorch/blob/main/daskTestRun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jB3eEm-WtRX8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import IterableDataset,DataLoader,Dataset\n",
        "import dask.array as da\n",
        "import torch\n",
        "from distributed import Client,LocalCluster\n",
        "from tqdm import tqdm\n",
        "import dask.dataframe as dd\n",
        "import dask\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(\"client\")\n",
        "logger.setLevel(logging.INFO)\n",
        "data_path='/content/sample_train.csv'"
      ],
      "metadata": {
        "id": "m02JSqz7uKHN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_batch(batch,NUM_WORKERS):\n",
        "    x, y = batch\n",
        "    x_chunks = x.chunk(NUM_WORKERS)\n",
        "    y_chunks = y.chunk(NUM_WORKERS)\n",
        "    return list(zip(x_chunks, y_chunks))\n",
        "\n",
        "def update_worker_model(state_dict):\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "def init_worker(main_model, main_criterion):\n",
        "    import logging\n",
        "    log = logging.getLogger(\"dask_worker_log\")\n",
        "    log.setLevel(logging.INFO)\n",
        "\n",
        "    global model, criterion\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = main_model.to(device)\n",
        "    criterion = main_criterion\n",
        "\n",
        "    log.info(f\"Successfully initialized model, and loss fn on worker withe device: {device}\")\n",
        "\n",
        "def all_reduce(results: list, model: torch.nn.Module):\n",
        "    avg_grads = [torch.zeros_like(p) for p in model.parameters()]\n",
        "\n",
        "    total_loss = dask.delayed(sum)([loss for loss, _ in results])\n",
        "    summed_grads = [dask.delayed(sum)([g[i] for _, g in results]) for i in range(len(avg_grads))]\n",
        "    computed_loss, computed_grads = dask.compute(total_loss, summed_grads)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for param, avg_grad in zip(model.parameters(), computed_grads):\n",
        "            param.grad = avg_grad / len(results)\n",
        "\n",
        "    return model, computed_loss\n",
        "\n",
        "def dispatch(client:Client,train,batch,model,criterion,optimizer):\n",
        "    client.run(init_worker, model, criterion)\n",
        "    NUM_WORKERS=len(list(client.scheduler_info()['workers'].keys()))\n",
        "    batches=split_batch(batch,NUM_WORKERS)\n",
        "    futures = client.map(train, batches)\n",
        "    results = client.gather(futures)\n",
        "\n",
        "    model,total_loss=all_reduce(results,model)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    client.run(update_worker_model, model.state_dict())\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "FHA2u4Ihthh9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKaCGrUWtRX-",
        "outputId": "7f895547-f15c-4891-8ae5-25462287f3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:40549\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n",
            "INFO:distributed.scheduler:Registering Worker plugin shuffle\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:39737'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:39949'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:43589'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:38951'\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:42181 name: 0\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:42181\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49844\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:34903 name: 2\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:34903\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49814\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:46079 name: 3\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:46079\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49812\n",
            "INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:44891 name: 1\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:44891\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49830\n",
            "INFO:distributed.scheduler:Receive client connection: Client-5396450a-1d3c-11f0-80be-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49850\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE=1000\n",
        "NUMBER_OF_WORKERS=4\n",
        "\n",
        "cluster=LocalCluster(n_workers=NUMBER_OF_WORKERS)\n",
        "client = Client(cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YcN5Uh3htRX_"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1=torch.nn.Linear(384,128)\n",
        "        self.fc2=torch.nn.Linear(128,64)\n",
        "        self.fc3=torch.nn.Linear(64,5)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=torch.relu(self.fc1(x))\n",
        "        x=torch.relu(self.fc2(x))\n",
        "        x=self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.df=self.fetch_data(path)\n",
        "\n",
        "    def fetch_data(self, path):\n",
        "        df=pd.read_csv(path)\n",
        "        return df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x= torch.tensor(json.loads(self.df[\"Embeddings\"][idx]))\n",
        "        y= self.df[\"OpenStatus\"][idx]\n",
        "        return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4iwtvt6stRYA"
      },
      "outputs": [],
      "source": [
        "model=Model()\n",
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "dataset=CustomDataset(path=data_path)\n",
        "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qgmDAzO6tRYA"
      },
      "outputs": [],
      "source": [
        "def train(batch):\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    x, y = batch\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model.to(device)(x)\n",
        "    loss = criterion(pred, y)\n",
        "    loss.backward()\n",
        "    return loss.item(),[p.grad.cpu() for p in model.parameters()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmMj6PXztRYA",
        "outputId": "27ead081-65d3-43b4-98e7-cc53064d4896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started at :http://127.0.0.1:8787/status\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:11<01:43, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 6.6157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:12<00:42,  5.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 6.4944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:13<00:22,  3.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 6.3749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:13<00:13,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 6.2497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:14<00:08,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 6.1127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:15<00:05,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss: 5.9598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:15<00:03,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss: 5.7866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:16<00:01,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss: 5.5893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:16<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss: 5.3655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:17<00:00,  1.75s/it]\n",
            "INFO:client:Took:1.4135619163513184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 5.1137\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training started at :{client.dashboard_link}\")\n",
        "total_time=[]\n",
        "for epoch in tqdm(range(10)):\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    for batch  in train_dataloader:\n",
        "        start=time.time()\n",
        "        total_loss=dispatch(client,train,batch,model,criterion,optimizer)\n",
        "        stop=time.time()\n",
        "        total_time.append(stop-start)\n",
        "        epoch_loss += total_loss\n",
        "        num_batches += 1\n",
        "    print(f\"Epoch {epoch+1} Loss: {epoch_loss/num_batches:.4f}\")\n",
        "\n",
        "logger.info(f\"Took:{sum(total_time)/len(total_time)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HumgnxAetRYB",
        "outputId": "291b9181-52cc-4657-b7b5-4a7fff51283b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:Remove client Client-5396450a-1d3c-11f0-80be-0242ac1c000c\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:49850; closing.\n",
            "INFO:distributed.scheduler:Remove client Client-5396450a-1d3c-11f0-80be-0242ac1c000c\n",
            "INFO:distributed.scheduler:Close client connection: Client-5396450a-1d3c-11f0-80be-0242ac1c000c\n",
            "INFO:distributed.scheduler:Retire worker addresses (stimulus_id='retire-workers-1745080562.0935268') (0, 1, 2, 3)\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:39737'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:39949'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:43589'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:38951'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:49844; closing.\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:49830; closing.\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:49814; closing.\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:49812; closing.\n",
            "INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:42181 name: 0 (stimulus_id='handle-worker-cleanup-1745080562.1510658')\n",
            "INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:44891 name: 1 (stimulus_id='handle-worker-cleanup-1745080562.1627233')\n",
            "INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:34903 name: 2 (stimulus_id='handle-worker-cleanup-1745080562.1640713')\n",
            "INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:46079 name: 3 (stimulus_id='handle-worker-cleanup-1745080562.1674032')\n",
            "INFO:distributed.scheduler:Lost all workers\n",
            "INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:39737' closed.\n",
            "INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:39949' closed.\n",
            "INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:43589' closed.\n",
            "INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:38951' closed.\n",
            "INFO:distributed.scheduler:Closing scheduler. Reason: unknown\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ],
      "source": [
        "# Cleanup\n",
        "client.close()\n",
        "cluster.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}